\BOOKMARK [0][]{titulo.0}{Folha de Rosto}{}% 1
\BOOKMARK [0][]{cip.0}{Verso da Folha de Rosto}{}% 2
\BOOKMARK [0][]{aprovacao.0}{Folha da Banca}{}% 3
\BOOKMARK [0][]{dedication.0}{Dedicat\363ria}{}% 4
\BOOKMARK [0][]{acknowledgment.0}{Agradecimentos}{}% 5
\BOOKMARK [0][]{epigrafe.0}{Ep\355grafe}{}% 6
\BOOKMARK [0][]{resumo.0}{Resumo}{}% 7
\BOOKMARK [0][]{abstract.0}{Abstract}{}% 8
\BOOKMARK [0][]{listafiguras.0}{Lista de Figuras}{}% 9
\BOOKMARK [0][]{listatabelas.0}{Lista de Tabelas}{}% 10
\BOOKMARK [0][]{listaabreviaturas.0}{Lista de Abreviaturas e Siglas}{}% 11
\BOOKMARK [0][]{listasimbolos.0}{Lista de S\355mbolos}{}% 12
\BOOKMARK [0][]{contents.0}{Sum\341rio}{}% 13
\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 14
\BOOKMARK [1][]{section.1.1}{1.1 Motivation}{chapter.1}% 15
\BOOKMARK [2][]{subsection.1.1.1}{1.1.1 AI Super Powers}{section.1.1}% 16
\BOOKMARK [2][]{subsection.1.1.2}{1.1.2 Deep Learning Revolution}{section.1.1}% 17
\BOOKMARK [2][]{subsection.1.1.3}{1.1.3 Reinforcement Learning}{section.1.1}% 18
\BOOKMARK [1][]{section.1.2}{1.2 Contextualization}{chapter.1}% 19
\BOOKMARK [2][]{subsection.1.2.1}{1.2.1 Simulated Soccer 2D}{section.1.2}% 20
\BOOKMARK [1][]{section.1.3}{1.3 Objective}{chapter.1}% 21
\BOOKMARK [1][]{section.1.4}{1.4 Scope}{chapter.1}% 22
\BOOKMARK [1][]{section.1.5}{1.5 Organization of this work}{chapter.1}% 23
\BOOKMARK [0][]{chapter.2}{2 Soccer 2D}{}% 24
\BOOKMARK [1][]{section.2.1}{2.1 How the Simulator Works}{chapter.2}% 25
\BOOKMARK [1][]{section.2.2}{2.2 Physical model of rcssserver}{chapter.2}% 26
\BOOKMARK [2][]{subsection.2.2.1}{2.2.1 Movement of the object}{section.2.2}% 27
\BOOKMARK [1][]{section.2.3}{2.3 Player Model}{chapter.2}% 28
\BOOKMARK [2][]{subsection.2.3.1}{2.3.1 Available Action Commands}{section.2.3}% 29
\BOOKMARK [1][]{section.2.4}{2.4 The Penalty Event}{chapter.2}% 30
\BOOKMARK [0][]{chapter.3}{3 Deep Reinforcement Learning}{}% 31
\BOOKMARK [1][]{section.3.1}{3.1 Markov Decision Processes}{chapter.3}% 32
\BOOKMARK [2][]{subsection.3.1.1}{3.1.1 Important Concepts}{section.3.1}% 33
\BOOKMARK [2][]{subsection.3.1.2}{3.1.2 The Bellman Equations}{section.3.1}% 34
\BOOKMARK [2][]{subsection.3.1.3}{3.1.3 About Solving It}{section.3.1}% 35
\BOOKMARK [2][]{subsection.3.1.4}{3.1.4 The Problem With The Tabular Solution}{section.3.1}% 36
\BOOKMARK [1][]{section.3.2}{3.2 Neural Networks}{chapter.3}% 37
\BOOKMARK [2][]{subsection.3.2.1}{3.2.1 Neurons}{section.3.2}% 38
\BOOKMARK [2][]{subsection.3.2.2}{3.2.2 The Network}{section.3.2}% 39
\BOOKMARK [2][]{subsection.3.2.3}{3.2.3 Cost Function and Gradient Descent}{section.3.2}% 40
\BOOKMARK [2][]{subsection.3.2.4}{3.2.4 Back Propagation}{section.3.2}% 41
\BOOKMARK [1][]{section.3.3}{3.3 Policy Gradient Methods, PPO}{chapter.3}% 42
\BOOKMARK [2][]{subsection.3.3.1}{3.3.1 Notation and Concepts}{section.3.3}% 43
\BOOKMARK [2][]{subsection.3.3.2}{3.3.2 Policy Approximation and its Advantages}{section.3.3}% 44
\BOOKMARK [2][]{subsection.3.3.3}{3.3.3 Policy Gradient Vanilla}{section.3.3}% 45
\BOOKMARK [2][]{subsection.3.3.4}{3.3.4 Actor Critic}{section.3.3}% 46
\BOOKMARK [2][]{subsection.3.3.5}{3.3.5 Proximal Policy Optimization \(PPO\)}{section.3.3}% 47
\BOOKMARK [0][]{chapter.4}{4 To Do List}{}% 48
\BOOKMARK [0][]{chapter.5}{Refer\352ncias}{}% 49
\BOOKMARK [0][]{bla.0}{Folha de Registro do Documento}{}% 50
